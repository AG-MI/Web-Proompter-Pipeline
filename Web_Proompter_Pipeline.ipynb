{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNh22kn9R5cuQJOSC++lJ6i"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ollama Server"
      ],
      "metadata": {
        "id": "kX1jl0gnJ-lF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the xterm shell"
      ],
      "metadata": {
        "id": "s84sRfJpKVjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm"
      ],
      "metadata": {
        "id": "J7W_SdpeKq8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the shell and:\n",
        "\n",
        "\n",
        "*   Install Ollama: ```curl https://ollama.com/install.sh -o install.sh``` ```sh install.sh```\n",
        "\n",
        "*   Start the Ollama Server: ```ollama serve &```\n",
        "\n",
        "*   Pull the DeepSeek-R1 1.5b Model: ```ollama pull deepseek-r1:1.5b```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FkQz3fspLEzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "1Xz68EDiNE-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Webserver"
      ],
      "metadata": {
        "id": "unb7LyOzJsze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the necessary dependencies for the web server"
      ],
      "metadata": {
        "id": "nJZmrTYP0UmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask\n",
        "!pip install langchain-community\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "Q5EzRJno0c3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember ```!ngrok authtoken '<authtoken>'```\n",
        "\n"
      ],
      "metadata": {
        "id": "alyEWfCnTpaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken ''"
      ],
      "metadata": {
        "id": "vcd6Ff7nXLM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the Flask routes/functions up and Ngrok"
      ],
      "metadata": {
        "id": "4CIK6GG70GXv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkfM7tMLnixT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import threading\n",
        "\n",
        "from flask import Flask\n",
        "from pyngrok import ngrok\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "os.environ['OLLAMA_HOST'] = '127.0.0.1:11434'\n",
        "app = Flask(__name__)\n",
        "port = \"5000\"\n",
        "\n",
        "# Open a ngrok tunnel to the HTTP server\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"\")\n",
        "\n",
        "# Update any base URLs to use the public ngrok URL\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "\n",
        "# Initialize the LLM model\n",
        "llm = Ollama(model=\"deepseek-r1:1.5b\")\n",
        "\n",
        "# Define Flask routes\n",
        "@app.route(\"/\")\n",
        "def generate_new_site():\n",
        "    response = llm.invoke(\"Generate a new website thats meant to troll people. All code has to be in one file. Answer only with the code, nothing else.\")\n",
        "    return response\n",
        "\n",
        "app.run()"
      ]
    }
  ]
}